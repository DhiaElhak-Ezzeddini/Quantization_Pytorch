{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0464bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06f9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=torch.manual_seed(0) ## make torch deterministic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcacc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])\n",
    "## Loading MNIST dataset\n",
    "mnist_train = datasets.MNIST(root='/data',train=True,download=True,transform=transform)\n",
    "mnist_test = datasets.MNIST(root='/data',train=False,download=True,transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=10,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3e28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassNetQuantized(nn.Module):\n",
    "    def __init__(self,  hidden_size_1=100,hidden_size_2=100):\n",
    "        super(ClassNetQuantized,self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.Linear1 = nn.Linear(28*28,hidden_size_1)\n",
    "        self.Linear2 = nn.Linear(hidden_size_1,hidden_size_2)\n",
    "        self.Linear3 = nn.Linear(hidden_size_2,10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.quant(x)\n",
    "        x = self.relu(self.Linear1(x))\n",
    "        x = self.relu(self.Linear2(x))\n",
    "        x = self.Linear3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a894b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "net = ClassNetQuantized().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e51b457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassNetQuantized(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (Linear1): Linear(\n",
       "    in_features=784, out_features=100, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (Linear2): Linear(\n",
       "    in_features=100, out_features=100, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (Linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.qconfig = torch.ao.quantization.default_qconfig\n",
    "net.train()\n",
    "net_quantized = torch.ao.quantization.prepare_qat(net)\n",
    "net_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe5c956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHIA\\AppData\\Local\\Temp\\ipykernel_10588\\2294997212.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(MODEL_FILE_NAME))\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader,model,epochs,total_iteration_limit=None) : \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    total_iterations = 0 \n",
    "    \n",
    "    for epoch in range(epochs) :\n",
    "        model.train()\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "        data_iterator = tqdm(train_loader,desc=f\"Epoch {epoch+1}\")\n",
    "        if  total_iteration_limit is not None:\n",
    "            data_iterator.total = total_iteration_limit\n",
    "        for data in data_iterator : \n",
    "            num_iterations += 1 \n",
    "            total_iterations += 1\n",
    "            x,y=data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x.view(-1,28*28))\n",
    "            loss = loss_fn(out,y)\n",
    "            loss_sum += loss\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if total_iteration_limit is not None and total_iterations >= total_iteration_limit:\n",
    "                return\n",
    "\n",
    "\n",
    "def print_size_model(model):\n",
    "    torch.save(model.state_dict(),\"temp_delme.p\")\n",
    "    print(f\"size (KB) :\" , os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove(\"temp_delme.p\")\n",
    "    \n",
    "MODEL_FILE_NAME = 'classnet.pt'\n",
    "if Path(MODEL_FILE_NAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILE_NAME))\n",
    "    print(f\"Model Loaded !\")\n",
    "else : \n",
    "    train(train_loader,net,epochs=2)\n",
    "    torch.save(net.state_dict(),MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20dd3f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6000/6000 [00:52<00:00, 113.88it/s, loss=tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)]\n",
      "Epoch 2: 100%|██████████| 6000/6000 [00:51<00:00, 116.17it/s, loss=tensor(0.1145, device='cuda:0', grad_fn=<DivBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "train(train_loader,net_quantized,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d5604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Stats collected during training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassNetQuantized(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
       "  )\n",
       "  (Linear1): Linear(\n",
       "    in_features=784, out_features=100, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.6958182454109192, max_val=0.4646841287612915)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-53.30250930786133, max_val=46.89039611816406)\n",
       "  )\n",
       "  (Linear2): Linear(\n",
       "    in_features=100, out_features=100, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.5422224998474121, max_val=0.4541158676147461)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-55.56305694580078, max_val=32.61673355102539)\n",
       "  )\n",
       "  (Linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.5476884841918945, max_val=0.22404539585113525)\n",
       "    (activation_post_process): MinMaxObserver(min_val=-53.4817008972168, max_val=28.439607620239258)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Checking Stats collected during training\")\n",
    "net_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd2c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efd478bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_quantized.eval()\n",
    "net_quantized = torch.ao.quantization.convert(net_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e880a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats of # layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassNetQuantized(\n",
       "  (quant): Quantize(scale=tensor([0.0256], device='cuda:0'), zero_point=tensor([17], device='cuda:0'), dtype=torch.quint8)\n",
       "  (Linear1): QuantizedLinear(in_features=784, out_features=100, scale=0.7889204621315002, zero_point=68, qscheme=torch.per_tensor_affine)\n",
       "  (Linear2): QuantizedLinear(in_features=100, out_features=100, scale=0.6943290829658508, zero_point=80, qscheme=torch.per_tensor_affine)\n",
       "  (Linear3): QuantizedLinear(in_features=100, out_features=10, scale=0.6450496912002563, zero_point=83, qscheme=torch.per_tensor_affine)\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Stats of # layers\")\n",
    "net_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d83889ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after quantization\n",
      "tensor([[ 2,  5, -4,  ...,  6,  2,  2],\n",
      "        [-6, -5, -4,  ..., -6, -3, -7],\n",
      "        [ 1,  8, -1,  ...,  1,  5,  7],\n",
      "        ...,\n",
      "        [11, 11,  5,  ...,  4,  8,  1],\n",
      "        [-3, -1,  5,  ...,  1,  1,  1],\n",
      "        [ 3,  2,  0,  ...,  6, -3,  1]], device='cuda:0', dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weights after quantization\")\n",
    "print(torch.int_repr(net_quantized.Linear1.weight()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33de74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,device,total_iterations=None):\n",
    "    correct=0\n",
    "    total=0\n",
    "    iterations=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader,desc=f\"Testing\") : \n",
    "            x,y=data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x.view(-1,28*28))\n",
    "            for idx,i in enumerate(out):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct+=1\n",
    "                total+=1\n",
    "            iterations+=1\n",
    "            if total_iterations is not None and iterations>= total_iterations : \n",
    "                break\n",
    "    print(f\"Accuracy : {round(correct/total,3)}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
